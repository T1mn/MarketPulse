"""å®¢æœ Agent"""
import logging
from typing import Dict, Any

from .base_agent import BaseAgent, AgentResponse
from core.llm.router import llm_router
from core.llm.prompt_manager import prompt_manager

logger = logging.getLogger(__name__)


class CustomerServiceAgent(BaseAgent):
    """
    å®¢æœ Agent

    èŒè´£ï¼š
    1. å¤„ç†ç”¨æˆ·å’¨è¯¢å’Œé—®é¢˜
    2. æä¾›ä½¿ç”¨å¸®åŠ©
    3. FAQ æŸ¥è¯¢
    4. é—®å€™å’Œé—²èŠ
    5. å¼•å¯¼åˆ°å…¶ä»– Agent
    """

    def __init__(self):
        super().__init__(
            name="customer_service",
            description="å®¢æœä¸“å‘˜ï¼Œå¤„ç†ç”¨æˆ·å’¨è¯¢ã€FAQã€ä½¿ç”¨å¸®åŠ©"
        )

        # å¯ä»¥å¤„ç†çš„æ„å›¾
        self.supported_intents = {
            "customer_service",
            "greeting",
            "chitchat",
        }

    async def can_handle(self, intent: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯ä»¥å¤„ç†è¯¥æ„å›¾"""
        return intent in self.supported_intents

    async def process(
        self,
        user_input: str,
        intent: str,
        entities: Dict[str, Any],
        context: Dict[str, Any],
        **kwargs
    ) -> AgentResponse:
        """å¤„ç†ç”¨æˆ·è¯·æ±‚"""
        logger.info(f"ğŸ‘¨â€ğŸ’¼ CustomerServiceAgent processing: {intent}")

        # æ ¹æ®ä¸åŒæ„å›¾å¤„ç†
        if intent == "greeting":
            return await self._handle_greeting(user_input, context)

        elif intent == "chitchat":
            return await self._handle_chitchat(user_input, context)

        elif intent == "customer_service":
            return await self._handle_customer_service(user_input, entities, context)

        else:
            return self._create_response(
                content="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚",
                confidence=0.5
            )

    async def _handle_greeting(
        self,
        user_input: str,
        context: Dict[str, Any]
    ) -> AgentResponse:
        """å¤„ç†é—®å€™"""
        # æ ¹æ®æ—¶é—´è¿”å›ä¸åŒçš„é—®å€™
        from datetime import datetime
        hour = datetime.now().hour

        if 5 <= hour < 12:
            greeting = "æ—©ä¸Šå¥½"
        elif 12 <= hour < 18:
            greeting = "ä¸‹åˆå¥½"
        else:
            greeting = "æ™šä¸Šå¥½"

        content = f"{greeting}ï¼æˆ‘æ˜¯ MarketPulse AIï¼Œæ‚¨çš„é‡‘èæ™ºèƒ½åŠ©æ‰‹ã€‚\n\næˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n" \
                  "ğŸ“Š æŸ¥è¯¢å¸‚åœºè¡Œæƒ…å’Œåˆ†æ\n" \
                  "ğŸ“° è§£è¯»é‡‘èæ–°é—»\n" \
                  "ğŸ’¼ æä¾›äº¤æ˜“å»ºè®®\n" \
                  "âš™ï¸ è®¾ç½®è‡ªåŠ¨åŒ–ä»»åŠ¡\n\n" \
                  "è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ"

        return self._create_response(
            content=content,
            confidence=1.0,
            metadata={"greeting_type": "time_based"}
        )

    async def _handle_chitchat(
        self,
        user_input: str,
        context: Dict[str, Any]
    ) -> AgentResponse:
        """å¤„ç†é—²èŠ"""
        # ä½¿ç”¨ LLM ç”Ÿæˆå‹å¥½çš„å›å¤
        system_prompt = """ä½ æ˜¯ MarketPulse AI çš„å®¢æœåŠ©æ‰‹ï¼Œå‹å¥½ã€ä¸“ä¸šã€æœ‰è¶£ã€‚
ç”¨æˆ·åœ¨å’Œä½ é—²èŠï¼Œè¯·ç»™å‡ºç®€çŸ­ã€å‹å¥½çš„å›å¤ï¼ˆä¸è¶…è¿‡50å­—ï¼‰ã€‚
é€‚å½“å¼•å¯¼ç”¨æˆ·å›åˆ°é‡‘èè¯é¢˜ã€‚"""

        try:
            # è·å–å¯¹è¯å†å²
            conversation_history = context.get("conversation_history", [])

            response = await llm_router.generate_with_history(
                conversation_history=conversation_history,
                user_input=user_input,
                system_prompt=system_prompt,
                model_preference="speed",
                temperature=0.8,  # ç¨é«˜æ¸©åº¦å¢åŠ è¶£å‘³æ€§
                max_tokens=200,
            )

            return self._create_response(
                content=response.content,
                confidence=0.9,
                metadata={"type": "chitchat"}
            )

        except Exception as e:
            logger.error(f"Chitchat error: {e}")
            return self._create_response(
                content="ğŸ˜Š å¾ˆé«˜å…´å’Œæ‚¨èŠå¤©ï¼æœ‰ä»€ä¹ˆé‡‘èé—®é¢˜éœ€è¦å¸®åŠ©å—ï¼Ÿ",
                confidence=0.7
            )

    async def _handle_customer_service(
        self,
        user_input: str,
        entities: Dict[str, Any],
        context: Dict[str, Any]
    ) -> AgentResponse:
        """å¤„ç†å®¢æœå’¨è¯¢"""
        # TODO: é›†æˆ RAG ä»çŸ¥è¯†åº“æ£€ç´¢ç­”æ¡ˆ
        # ç°åœ¨å…ˆä½¿ç”¨ LLM ç”Ÿæˆ

        # æ„å»º Promptï¼ˆä½¿ç”¨ PromptManagerï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥è°ƒç”¨ LLM
        system_prompt = """ä½ æ˜¯ MarketPulse AI çš„å®¢æœä¸“å‘˜ã€‚

å¸¸è§é—®é¢˜ï¼š
1. å¦‚ä½•å……å€¼ï¼Ÿ- æ”¯æŒé“¶è¡Œå¡ã€æ”¯ä»˜å®ã€å¾®ä¿¡æ”¯ä»˜
2. å¦‚ä½•ä¿®æ”¹å¯†ç ï¼Ÿ- è¿›å…¥"è®¾ç½®"->"å®‰å…¨"->"ä¿®æ”¹å¯†ç "
3. äº¤æ˜“è´¹ç”¨ï¼Ÿ- è‚¡ç¥¨äº¤æ˜“ 0.1%ï¼ŒåŠ å¯†è´§å¸ 0.05%
4. å®¢æœæ—¶é—´ï¼Ÿ- 7x24 å°æ—¶åœ¨çº¿æœåŠ¡

è¯·ç®€æ´ã€å‡†ç¡®åœ°å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœä¸ç¡®å®šï¼Œå»ºè®®è”ç³»äººå·¥å®¢æœã€‚
æ³¨æ„ï¼šä½ å¯ä»¥å‚è€ƒä¹‹å‰çš„å¯¹è¯å†å²æ¥ç†è§£ç”¨æˆ·çš„é—®é¢˜ä¸Šä¸‹æ–‡ã€‚"""

        try:
            # è·å–å¯¹è¯å†å²
            conversation_history = context.get("conversation_history", [])

            response = await llm_router.generate_with_history(
                conversation_history=conversation_history,
                user_input=user_input,
                system_prompt=system_prompt,
                model_preference="balanced",
                temperature=0.3,
                max_tokens=500,
            )

            return self._create_response(
                content=response.content,
                confidence=0.85,
                metadata={"type": "faq"}
            )

        except Exception as e:
            logger.error(f"Customer service error: {e}")
            return self._create_response(
                content="æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚è¯·è”ç³»äººå·¥å®¢æœè·å–å¸®åŠ©ã€‚",
                confidence=0.5
            )
